## 线程安全、锁、线程间通信

### 线程安全问题

**线程安全**：在**多线程环境**下，通过**同步确保多线程访问共享变量**的代码符合预期逻辑，**正确的同步需要处理并发编程三大特性**：
- **同步/异步的语义**：
  - 在JavaIO和Future中，同步指是否等待数据就绪（同步非阻塞指在等待就绪的过程中可以完成其他任务），异步指数据就绪后调用回调函数
  - **在并发控制中，同步和异步指线程间是否有协同与互斥**
- **原子性代码块**：**在逻辑上不可分割**，其**中间状态对外部线程不可见**，称为临界区
  - 即使正在执行临界区代码的线程发生上下文切换，其他**受同步机制约束的线程**也无法进入该临界区
  - 若有线程未受同步机制约束则将破坏原子性，可以观测到其他线程修改共享变量操作的开始状态、中间状态、结束状态，造成严重的数据不一致和逻辑错误问题
  - **数据库事务的原子性**确保一个或一组事务要么不可中断地全部执行，要么都不执行，若执行错误就执行回滚操作
  - **并发原子性**通过线程执行的互斥性确保不可观测到中间态
- **可见性共享变量**：当一个线程修改了可见性共享变量的值，其他线程能够立即得知这一修改。
- **有序性代码块**：避免指令重排序后，并发环境下的代码执行顺序不符合逻辑预期


#### 线程原子性与上下文切换

程序员希望高级语言中的一行代码是原子性的，但是一条代码往往不是原子性的，**对Cpu而言一行代码往往会编译为多条指令，因为Cpu无法辨别哪些指令属于一个不可分割的整体，所以可以在多条指令执行的间隙执行上下文切换，导致其他线程可以获取共享变量的中间状态，引发数据不一致问题**
- 在两个未同步的线程中，对共享变量i执行i++操作：对Cpu而言i++是Read、Modify、Write三个原子性指令的组合，当上下文切换在原子性指令执行的间隙发生时，其他线程将重复修改共享变量，导致更新丢失

```JAVA
public class Main {
    private static int counter = 0;

    public static void main(String[] args) throws InterruptedException {
        // 创建两个线程，每个线程自增 10,000 次
        Runnable task = () -> {
            for (int i = 0; i < 10000; i++) {
                counter++; // 非原子操作
            }
        };

        Thread t1 = new Thread(task);
        Thread t2 = new Thread(task);

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        // 最终输出结果小于 20000
        System.out.println("理论预期值: 20000");
        System.out.println("实际运行值: " + counter);
        System.out.println("丢失更新数: " + (20000 - counter));
    }
}

```

#### 线程可见性与Cpu多级缓存

现代计算机通过**Cpu多级缓存**解决了Cpu运算速度与主存读写速度不匹配的问题，通过**MESI 缓存一致性协议**解决**缓存一致性**问题，但是需要由软件自行解决**可见性**问题
- **局部性原理**：缓存的有效性基于两个关键假设
  - **时间局部性**：如果一个数据被访问，那么近期它极可能再次被访问
  - **空间局部性**：如果一个数据被访问，那么它相邻的数据也极可能很快被访问，因此多级缓存读写主存**以缓存行为单位**
- **Cpu多级缓存架构**

| 层级 | 真实位置 | 模拟耗时 (假设 CPU 算一下是 1秒) | 容量 | 角色隐喻 |
| --- | --- | --- | --- | --- |
| **寄存器 (Registers)** | **CPU 核心内部** | **1 秒** (即时) | 极小 (几百字节) | **手中的加工件**。CPU 只能直接计算这里的数据。 |
| **L1 Cache** | **CPU 核心内部** | **3 ~ 4 秒** | 小 (32KB - 64KB) | **工位上的工具箱**。伸手就能拿。 |
| **L2 Cache** | **CPU 核心内部** | **10 ~ 12 秒** | 中 (256KB - 512KB) | **身后的背包**。转身就能拿。 |
| **L3 Cache** | **多核共享** | **40 ~ 50 秒** | 大 (MB ~ 几十 MB) | **房间里的共享货架**。所有核心都能看到。 |
| **主存 (DRAM)** | **插在主板上** | **200 ~ 300 秒 (几分钟)** | 巨大 (GB ~ TB) | **楼下的仓库**。去一趟很慢。 |

- **MESI 缓存一致性协议**：确保多个Cpu核心同时缓存主存中的同一行数据时的数据一致性
  - 缓存行共四种状态
    - M-Modified：**缓存行被修改**，与主存不一致，且只存在于当前 Cache 中。
    - E-Exclusive：**缓存行与主存一致**，且只存在于当前 Cache 中。
    - S-Shared：**缓存行与主存一致**，可能存在于多个核心的 Cache 中。
    - I-Invalid：**缓存行已失效**
- **寄存器导致读操作可见性延迟**：
  - 寄存器不在MESI缓存一致性协议生效范围内，Java即时编译器JIT分析代码执行次数，并在寄存器中维护**高频访问的共享变量副本**，不再从Cpu高速缓存中重新读取共享变量
  - 主线程修改主存并同步更新到执行子线程的Cpu的高速缓存中，但是子线程的Cpu在寄存器中维护了变量副本，不会感知其修改，导致可见性延迟


```JAVA
public class Main {
    public static boolean flag = true;
    //空循环并且让主线程睡眠一会儿，让JIT编译器检测热代码将flag放在寄存器里
    public static void main(String[] args) throws InterruptedException {
        new Thread(() -> {
            System.out.println("子线程：开始执行，等待 flag 变为 false...");
            while (flag) {}
            //即使一秒后主线程修改flag，子线程也无法退出
            System.out.println("子线程：检测到 flag 变为 false，退出循环！");
        }).start();
        Thread.sleep(1000);
        flag = false;
        System.out.println("主线程：已将 flag 修改为 false");
    }
}
```



- **Store Buffer写缓冲导致写操作可见性延迟**：
  - Cpu核心修改缓存行时必须发送Invalidate 消息给其他核心并等待ACK回复后写入主存，为避免Cpu流水线卡顿先将修改写入缓冲区并继续执行后续指令；其他核心收到Invalidate 消息后使目标缓存行失效，并重新从主存读取目标缓存行，可能因为修改仍在写缓冲区而读取到旧值，导致逻辑上的指令重排序，即实际上指令的执行顺序是先写后读，而逻辑上的指令执行顺序却变成了先读后写，在单线程环境下，由于是一个Cpu核心，所以该逻辑重排序永远不会发生
  - 线程1、2的Cpu核心都仅执行两条代码，如果没有写缓冲，那么一定是先写后读，则最后结果可能是(1,1), (0,1), (1,0)，当先读后写发生时，a和b都读取到旧值0（实际上已经执行了原子指令x和y的赋值），导致逻辑上的错误结果(0,0)



```java
public class Main {
    private static int x = 0, y = 0;
    private static int a = 0, b = 0;
    private static int count01=0;
    private static int count10=0;
    private static int count11=0;

    public static void main(String[] args) throws InterruptedException {
        int count = 0;
        while (true) {
            count++;
            x = 0; y = 0; a = 0; b = 0;

            // 线程 1
            Thread t1 = new Thread(() -> {
                x = 1;  // 写操作
                a = y;  // 读写操作
            });

            // 线程 2
            Thread t2 = new Thread(() -> {
                y = 1;  // 写操作
                b = x;  // 读写操作
            });

            t1.start();
            t2.start();
            t1.join();
            t2.join();

            if (a == 0 && b == 1) {
                count01++;
            }
            if (a == 1 && b == 0) {
                count10++;
            }
            if (a == 1 && b == 1) {
                count11++;
            }

            if (a == 0 && b == 0) {
                System.err.println("第 " + count + " 次实验出现异常：(a=0, b=0)");
                System.out.println("(0,1)出现次数："+count01);
                System.out.println("(1,0)出现次数："+count10);
                System.out.println("(1,1)出现次数："+count11);
                break;
            }
        }
    }
}
```


**伪共享与缓存行填充**
- 无关线程安全，但是影响线程性能；
- Cpu高速缓存和主存之间的读写以行为单位，在64位机中，缓存行是64字节
- **伪共享**：如果不相关的变量A和变量B在同一个缓存行中，线程修改变量A导致缓存行失效，拖慢其他线程对变量B的读写
- **缓存行填充Padding**：通过填充大量long类型空白行，将相邻的变量挤到不同的缓存行里

#### 线程有序性与指令重排序

对Cpu而言程序只不过是一段指令，即**指令流水线**，为了不让流水线中断，需要指令重排序
```JAVA
a=b+c
e=e-f
```
- 考虑上述两条代码，翻译为指令都是加载和计算指令，为了不在加载时停顿，通过指令重排序连续加载b、c、e、f，然后再顺序执行两次计算
- 指令重排序保证单线程环境下程序语义不变，但在多线程环境下可能由于乱序而出现程序错误
**指令重排序分为三种**
- **编译器优化重排**，编译器在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
- **指令并行重排**，现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。
- **多级缓存导致的逻辑上的指令重排序**



### Java内存模型

> **首先区分[Java运行时内存区域](#jvm运行时内存区域)和Java内存模型两个不同又有联系的概念**，Java运行时内存区域是**JVM运行时的具体物理内存划分**，如堆、栈、方法区，而Java内存模型是一套抽象的逻辑协议
- JMM协议**屏蔽了底层复杂的硬件架构**，无需从Cpu、寄存器、多级缓存和汇编指令的角度，而是从线程与内存交互的视角处理线程安全问题
- **JMM协议由四部分组成：逻辑架构、8种原子性操作、Happens-Before 规则、内存屏障；**


#### 逻辑架构

1. **主存**：所有线程共享的内存区域（注意并不是实际的主存DRAM，而是抽象的逻辑概念）
2. **工作内存**：每个线程独占的内存区域
3. **交互协议**：
   - 线程对共享变量的所有操作都视为仅在工作内存中进行。
   - 线程首次获取变量时，从主存拷贝到工作内存，修改后视情况刷新回主存
   - 不同线程之间无法直接访问彼此的工作内存，线程间的通信必须通过主存作为中介完成。

#### 8种原子性操作

JMM定义了8种不可分割的原子操作，是线程读写主存的最小单位；JMM将底层的Cpu和指令流抽象为线程和8种原子性操作。除非一定要涉及底层硬件，后续文章统一从线程和内存操作的抽象视角出发审视源码
- **Read/Load**：从主存传输到工作内存，把 read 得到的值放入工作内存的变量副本中。

- **Use/Assign**：把工作内存的值传递给Cpu，Cpu处理完后赋值给工作内存变量。

- **Store/Write**：把工作内存的值传送到主存，把 store 得到的值放入主存变量中。

- **Lock/Unlock**：作用于主存，将变量标识为线程独占或释放状态

**约束**
- Read/Load 与 Store/Write 必须成对出现，因为有读可见性延迟、写可见性延迟和指令重排序，所以两个内存操作不一定相邻
- 执行Assign，则必定**在之后某个时间点**执行Store/Write；不执行Assign，则不允许执行Store/Write
- Lock/Unlock是`synchronized`重量级锁的底层抽象
  - **排他性**：同一个变量在同一时刻只允许一个线程对其进行Lock操作，如果该变量已被锁，其他线程必须阻塞等待；
  - **不可分割的操作块**：成功执行Lock操作的线程将获得一个语义上的原子块。在这个块内，无论它执行了多少次 Read/Use/Assign，其他线程都无法介入该变量的交互。同时清空工作内存中该变量的副本，执行Read/Load操作从主存获取最新值
  - **UnLock**：执行多少次Lock操作就必须执行多少次Unlock操作，才能完全释放变量的所有权；同时执行 Unlock操作前，执行Store/Write =操作强制将结果推回主存

**实现同步的最小周期**：
- Read-Load-Use：线程放弃本地缓存从主存获取最新值，避免线程永远在过期的副本上工作
- Assign-Store-Write：线程修改数据并在以后某个时间点写回主存
- Lock/Unlock：定义临界区，临界区内的操作是**无法被其他线程分割的整体**

#### 内存屏障

JMM协议中的内存屏障操作是Java实现可见性和有序性的底层抽象工具，但不提供原子性，**有序性通过禁止重排序实现，而屏障通过干预Cpu缓存机制来禁止重排序，从而提供可见性**
- **读屏障LoadLoad, LoadStore**：该线程执行读屏障指令时，将确保工作内存中的所有数据与主内存一致，确认一致后才能执行屏障后指定的Load或Store指令
- **写屏障StoreStore、StoreLoad**：该线程执行写屏障指令时，将工作内存中所有修改过的数据写回主内存，确认全部写回后才能执行屏障后的Store指令或Load指令
- **全能屏障StoreLoad**：StoreLoad屏障兼具其他三种屏障的功能，其语义是所有修改都写入主存后才允许读，为了不破坏数据一致性，会同时禁止Load指令和Store指令重排序到屏障前，并且无效化工作内存变量重新读取；
- StoreLoad是x86架构中唯一真实存在的物理屏障，禁止所有指令提前，会造成Cpu卡顿。其他三种操作都只是空操作，仅提供标记作用，仍有指令是可以提前的，不会造成Cpu卡顿。所以通常组合其他三种屏障来确保同步，不到万不得已不会使用StoreLoad


| 屏障类型 | 指令示例 | 有序性 | 实现该有序性提供的可见性 | 应用场景举例 | 性能开销 |
| --- | --- | --- | --- | --- | --- |
| **LoadLoad** | `Load1; LoadLoad; Load2` | 确保 Load1 先于 Load2 读取 | 无效化本地缓存，强迫重读主存，重读结束后才能执行Load2 | 先读取引用，再通过引用读取字段 | 低 |
| **StoreStore** | `Store1; StoreStore; Store2` | 确保 Store1 先于 Store2 写入 | 将写缓冲区刷新到主存，全部写入后才能执行Store2 | new实例时，确保内存初始化结束后才进行引用赋值 | 低 |
| **LoadStore** | `Load1; LoadStore; Store2` | 确保 Load1 先于 Store2 执行 | 等待 Load1 完成再允许写入 | 防止还没读完旧值就被后续的写覆盖 | 中 |
| **StoreLoad** | `Store1; StoreLoad; Load2;Store3` | 确保 Store1 先于 Load2 执行 | 为确保数据一致性，停止Cpu等待清空写缓冲、无效化缓存结束后才能执行Load2和Store3 | `volatile`变量的写操作后插入该屏障 | **高** |



#### Happens-Before规则

JMM逻辑架构抽象了硬件底层架构，8种原子性操作抽象了硬件底层操作，内存屏障封装了Cpu控制指令流执行顺序的硬件底层操作，JMM进一步将复杂的内存屏障组合封装为一种**可见性声明**，即**Happens-Before规则**：**如果操作A Happens-Before 操作B，那么JMM保证：操作 A 的结果对于操作 B 而言是可见的，且操作 A 的顺序位在 B 之前。**


JMM定义8种天然的Happens-Before规则
1. **程序次序规则**：在一个线程内，书写在前面的操作 Happens-Before 后面的操作。
   - 不保证其他线程的观测结果，即由于指令重排序，其他线程可能先看到后面操作的执行结果，
   - 即使发生指令重排序，由于指令重排序技术都确保单线程执行结果的正确性，同一个线程仍能天然地正确观测到前面操作的执行结果，例如先初始化实例，再调用引用更改器不会报错空指针
2. **Lock/Unlock规则**：一个 unlock 操作 Happens-Before 后面对同一个锁的 lock 操作
   - 执行unlock操作前必须将工作内存中的修改刷回主内存，执行lock操作必须先load最新值
3. **Volatile规则**：对一个 volatile 变量的写操作 Happens-Before 后面对这个变量的读操作。
   - volatile 变量写操作后插入StoreLoad 全能屏障，确保后续读操作一定读取到最新变量
4. **线程启动规则**：Thread 对象的 start() 方法 Happens-Before 该线程中的每一个动作。
   - 保证了主线程在启动子线程前修改的共享变量，在子线程开始执行时都是可见的。
5. **线程终止规则**：线程中的所有操作都 Happens-Before 其它线程检测到该线程已经终止
   - 其他线程执行join等操作时，一定能读取到该线程的所有修改
6. **对象终结规则**：一个对象的初始化完成Happens-Before 该对象被GC之前
7. **传递性**：如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C
   - 最强大的规则，将上述孤立的七条规则联系在一起，例如与程序次序规则结合，将普通变量的读写操作书写在 volatile写操作之前，或者将普通变量的读写书写在临界区中，确保隐式同步，



# ----编辑中----


  - **逻辑架构**：**线程与主存、工作内存进行交互的规则**
  - **8种原子性操作**
  - Happens-Before 规则和内存屏障定义**多线程环境下共享变量的访问规则**：**通过Happens-Before 规则确保同步**，**通过内存屏障实现共享变量可见性并禁止指令重排序**

**多线程环境下共享变量的访问规则**
- JMM通过解决线程间的通信和同步问题，满足并发编程三大特性：**原子性、有序性、可见性**
- JMM 通过内存屏障实现可见性和禁止重排序，为了用户方便理解该系列规则，设计者提出**Happens-Before概念**


**多线程环境程序是否正确取决于是否满足原子性、有序性、可见性**，即线程安全问题
- **线程安全问题**：多个线程同时访问并修改同一数据且缺乏适当的同步措施时造成线程安全问题
- 线程安全问题需要通过满足原子性、有序性、可见性解决
- **原子性Atomicity**
  - 原子性指一个操作是不可中断的整体，要么全部执行成功，要么完全不执行
  - 现代64位JVM中，**基本数据类型的单次读写是原子性的**
- **可见性Visibility**
  - 可见性指当一个线程修改了共享变量的值，其他线程能够立即感知到这个修改
  - **`volatile`**：强制将修改后的值立即刷新回主存，并利用缓存一致性协议（如 MESI）使其他线程的缓存行失效。
  - **`synchronized`**：在释放锁之前，必须将工作内存中的变量同步回主存。
  - **`final`**：被 `final` 修饰的字段在构造器初始化完成后，对其他线程即是可见的
- **有序性Ordering**
  * 有序性指程序执行的顺序按照代码的先后顺序执行

除了线程安全问题，多线程环境程序还需要考虑**活跃性问题**和**性能问题**
- **活跃性问题**
  - **死锁**：两个或多个线程互相持有对方所需的资源，同时等待对方释放资源，导致所有相关线程永久阻塞
  - **活锁**：两个或多个线程没有阻塞并且都在修改各自的状态，而其他线程又依赖这个状态，就导致任何一个线程都无法继续执行，只能重复着自身的动作
  - **饥饿**：
    - 高优先级的线程一直在运行消耗 CPU，所有的低优先级线程一直处于等待
    - 一些线程被永久堵塞在一个等待进入同步块的状态，而其他线程总是能在它之前持续地对该同步块进行访问；
- **性能问题**
  - 多线程有创建线程和线程上下文切换的开销，这种昂贵的开销是需要操作系统完成的，导致多线程并发不一定比单线程串行执行快

---



多线程安全问题，多线程环境程序还需要考虑活跃性问题和性能问题，
- 活跃性问题
  - 死锁：



### JMM与重排序


指令重排序通过减少Cpu停顿时间，不让指令流水线中断，而提高Cpu的效率
- 下面两条指令都需要先加载再计算，为了不在加载时停顿，通过指令重排序连续加载b、c、e、f，然后再连续执行两次计算
- **指令重排序对于提高 Cpu 性能十分必要，该技术保证单线程环境下程序语义不变，但在多线程环境下带来了乱序的问题**
```JAVA
a=b+c
e=e-f
```

**指令重排序分为三种**
- **编译器优化重排**，编译器在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
- **指令并行重排**，现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。
- **内存系统重排**，由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

**JMM 与顺序一致性模型**
- 当程序未正确同步的时候，就可能存在**数据竞争：在一个线程中写一个变量，在另一个线程读同一个变量，并且写和读没有通过同步来排序**。
- **数据竞争发生时，程序的运行结果是不确定的**，即**同一个变量的读写操作发生的先后顺序是不确定的**
- **JMM承诺**：**正确同步的程序，其执行结果具有顺序一致性**，即该程序在多线程环境下和单线程环境下（顺序一致性模型）的执行结果相同
- **JMM不保证**未正确同步的程序的顺序一致性，因为JMM不仅需要减少用户编程的工作量，还需要尽量兼顾编译期和处理器的大量优化操作
- 但是JMM为未同步程序提供**最小化安全性**：对于未同步的线程，线程读取到的值，要么是之前某个线程写入的值，要么是默认值
  - 实现机制：**实例化对象操作是同步的**，即：内存空间清零，和在该内存空间分配对象两个操作是同步的。
- JMM与顺序性一致模型的差异：
  - JMM 不保证单线程内的操作会按程序的顺序执行
  - JMM 不保证所有线程能看到一致的操作执行顺序
  - JMM 不保证对 64 位的 `long` 型和 `double` 型变量的写操作具有原子性；在32位JVM中，会拆分为两次独立的高位、低位复合操作

**Happens-Before**
- 开发者希望强约束内存模型；编译器和处理器希望弱约束内存模型，以尽可能多的做优化来提高性能。
- JMM向编译器和处理器要求：只要满足正确同步的程序的顺序一致性，编译器和处理器怎么优化都行
- JMM向开发者提供简单易懂的**Happens-Before** 规则，提供了足够强的内存可见性保证
- **Happens-Before**规则**定制了两个同一线程内或不同线程间的操作之间的执行顺序**
  - **操作1 Happens-Before 操作2，则操作1的执行结果对操作2可见（即使它们不在同一个线程内），且操作1的执行顺序排在操作2之前（即使它们不在同一个线程内）。**
  - 操作1 Happens-Before 操作2，不代表JVM必须要按照 Happens-Before 关系指定的顺序来执行，如果重排序之后的执行结果，与按 Happens-Before 关系来执行的结果一致，那么 JMM 也允许这样的重排序。**否则，禁止重排序**


1. **程序次序规则 (Program Order Rule)**：在一个线程内，按照代码顺序，书写在前面的操作 Happens-Before 书写在后面的操作。
2. **监视器锁规则 (Monitor Lock Rule)**：一个 `unlock` 操作 Happens-Before 后续对同一个锁的 `lock` 操作。这是 `synchronized` 可见性的理论基础。
3. **volatile 变量规则**：对一个 `volatwile` 变量的写操作 Happens-Before 后续对这个变量的读操作。
4. **传递性 (Transitivity)**：如果 A Happens-Before B，且 B Happens-Before C，则 A Happens-Before C。
5. **线程启动/终止规则**：`Thread.start()` Happens-Before 该线程内的任何操作；线程内的所有操作 Happens-Before 其他线程检测到该线程结束（`Thread.join()` 返回）。




---

